import numpy as np
import pandas as pd
from langdetect import detect
from nltk.tokenize import ToktokTokenizer
import string
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer, SnowballStemmer
import re
import nltk
import pyarabic.araby as ar
import re , emoji, Stemmer, functools, operator, string
from nltk.stem.isri import ISRIStemmer
#nltk.download('wordnet')
#nltk.download('stopwords')


# NLP pipeline classes for Arabic and English

class ArabicPreprocessor:
    def __init__(self):
        self.stop_words = set(stopwords.words('arabic'))
        self.st =  Stemmer.Stemmer('arabic')
        self.snowball_stmmer = SnowballStemmer("arabic")
        self.isris_stemmer = ISRIStemmer()
        
    def preprocess(self, text):
        # Replace one or more whitespace characters with a single space
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # Remove elongation
        text = re.sub(r'(.)\1+', r"\1", text) 
        
        # Normalize letters
        text = re.sub("Ù‰", "ÙŠ", text)
        text = re.sub("Ø¤", "Ø¡", text)
        text = re.sub("Ø¦", "Ø¡", text)
        text = re.sub("Ø©", "Ù‡", text)
        text = re.sub("[Ø¥Ø£Ù±Ø¢Ø§]", "Ø§", text)

        # Remove repetetions
        text = text.replace('ÙˆÙˆ', 'Ùˆ')
        text = text.replace('ÙŠÙŠ', 'ÙŠ')
        text = text.replace('ÙŠÙŠÙŠ', 'ÙŠ')
        text = text.replace('Ø§Ø§', 'Ø§')
        
    
        # Remove tashkeel and tatweel
        text = ar.strip_tashkeel(text)
        text = ar.strip_tatweel(text)

        # Remove punctuation marks
        text = text.translate(str.maketrans('', '', string.punctuation))
        
        
        # Replacing with synonyms and replacing expressions with meaningful words
        
        # Words or expressions associated with a good review
        text = text.replace('Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù‡', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø§Ø­Ù„Ø§', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø§Ø­Ù„ÙŠ', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø§Ø®Ù„ÙŠ', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø§Ø­Ù„Ù‡', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø·ÙŠØ¨', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø­Ù„Ùˆ', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ÙŠØ¬Ù†', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ÙŠØ¬Ù†Ù†', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø§ÙØ¶Ù„', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('wow', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø³Ø±ÙŠØ¹', 'Ù…Ù…ØªØ§Ø²')        
        text = text.replace('ÙƒÙˆÙŠØ³Ø©', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ÙƒÙˆÙŠØ³', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ØªÙˆÙÙŠÙ‚', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø¬Ù…ÙŠÙ„', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø¬Ù…ÙŠÙ„Ø©', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø³Ù‡Ù„', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø´ÙƒØ±', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø´ÙƒØ±Ø§', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø¬ÙŠØ¯', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø±ÙˆØ¹Ù‡', 'Ù…Ù…ØªØ§Ø²')
        
        text = text.replace('Ù†Ø¸ÙŠÙ', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø§Ù‚ÙˆÙ‰', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ù‚ÙˆÙ‰', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ù…Ù†ØªØ§Ø²', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('perfect', 'Ù…Ù…ØªØ§Ø²')



        # Words associated usually with a bad review (also some of them are removed as stop words but they are useful)
        text = text.replace('bad', 'Ø²ÙØª')
        text = text.replace('ÙØ§Ø´Ù„', 'Ø²ÙØª')
        text = text.replace('Ø®ÙŠØ³', 'Ø²ÙØª')
        text = text.replace('Ø¹Ø³ÙŠØ±', 'Ø²ÙØª')
        text = text.replace('Ù…Ø´ÙƒÙ„Ù‡', 'Ø²ÙØª')
        text = text.replace('Ù…Ø´Ø§ÙƒÙ„', 'Ø²ÙØª')
        text = text.replace('Ø¹Ø³ÙŠØ±', 'Ø²ÙØª')
        text = text.replace('Ù†ØµØ¨', 'Ø²ÙØª')
        text = text.replace('Ø§Ø­ØªÙŠØ§Ù„', 'Ø²ÙØª')
        text = text.replace('ØµØ¹Ø¨', 'Ø²ÙØª')
        text = text.replace('ÙŠÙ„Ø¹', 'Ø²ÙØª')
        text = text.replace('ÙŠÙ„Ø¹Ù†', 'Ø²ÙØª')
        text = text.replace('ÙŠØªØ£Ø®Ø±', 'Ø²ÙØª')
        text = text.replace('Ø¨Ø§ÙŠØ®', 'Ø²ÙØª')
        text = text.replace('Ø§Ø³ÙˆØ¡', 'Ø²ÙØª')
        text = text.replace('Ù…ÙÙŠØ´', 'Ø²ÙØª')
        text = text.replace('ØªÙÙˆ', 'Ø²ÙØª')
        
        text = text.replace('Ø¶ØºÙŠÙ', 'Ø²ÙØª')
        text = text.replace('Ù„Ø§ ÙŠØ¹Ù…Ù„', 'Ø²ÙØª')
        text = text.replace('Ø°Ù‚', 'Ø²ÙØª')
        text = text.replace('ÙŠØ³Ø±Ù‚', 'Ø²ÙØª')
        text = text.replace('ÙŠÙ„ØºÙŠ', 'Ø²ÙØª')
        text = text.replace('Ù„ØµÙˆØµ', 'Ø²ÙØª')
        text = text.replace('Ø®Ø§ÙŠØ³', 'Ø²ÙØª')
        text = text.replace('Ø§ÙØ´Ù„', 'Ø²ÙØª')
        text = text.replace('ØºØ¨ÙŠ', 'Ø²ÙØª')
        text = text.replace('Ù„Ù„Ø§Ø³Ù', 'Ø²ÙØª')
        text = text.replace('Ø®Ø±Ø§', 'Ø²ÙØª')
        text = text.replace('Ù‚Ø°Ø±', 'Ø²ÙØª')
        text = text.replace('Ù‚Ø²Ø±', 'Ø²ÙØª')
        text = text.replace('Ø§ÙŠ ÙƒÙ„Ø§Ù…', 'Ø²ÙØª')
        text = text.replace('Ø¨Ø®Ø²Ù‰', 'Ø²ÙØª')
        text = text.replace('Ù…Ù†Ù‡Ù… Ù„Ù„Ù‡', 'Ø²ÙØª')
        text = text.replace('khara', 'Ø²ÙØª')  
        text = text.replace('Ø·Ø¸', 'Ø²ÙØª')  



        # replacing most common emojis with equivalent words
        text = text.replace('ğŸ‘', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ˜˜', 'Ù…Ù…ØªØ§Ø²')        
        text = text.replace('ğŸ‘Œ', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ˜', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ˜Š', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’™', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’•', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’œ', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ‘', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ˜‹', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ˜', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ¥°', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ¤©', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ”¥', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ¤—', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ˜‰', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’“', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’‹', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’›', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’—', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ–’', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('ğŸ’–', 'Ù…Ù…ØªØ§Ø²')

        text = text.replace('ğŸ¤¬', 'Ø²ÙØª')
        text = text.replace('ğŸ˜¤', 'Ø²ÙØª')
        text = text.replace('ğŸ˜’', 'Ø²ÙØª')
        text = text.replace('ğŸ˜¢', 'Ø²ÙØª')
        text = text.replace('ğŸ˜­', 'Ø²ÙØª')
        text = text.replace('ğŸ˜ ', 'Ø²ÙØª')
        text = text.replace('ğŸ˜¡', 'Ø²ÙØª')
        text = text.replace('ğŸ‘', 'Ø²ÙØª')
    
        
        # # Remove stop words (Ù„Ø§ Ùˆ ØºÙŠØ± Ø¨ÙŠØºÙŠØ±Ùˆ Ù…Ø¹Ù†ÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©)
        # words_to_remove = {'Ù„Ø§', 'ØºÙŠØ±', 'Ù…Ø§', 'Ù„Ù…'}

        # # Remove the specified words from the set of Arabic stopwords
        # arabic_stopwords = self.stop_words - words_to_remove
        # text = ' '.join([word for word in text.split() if word.lower() not in arabic_stopwords])
        
        # Stem the words in the text (Try different stemmers)
        
        # Stemmer library
        text = " ".join([self.st.stemWord(word) for word in text.split()])
        
        # Snowball stemmer
        #text = " ".join([self.snowball_stmmer.stem(word) for word in text.split()])
        
        # Isris stemmer
        # text = self.isris_stemmer.stem(text)
        # text = self.isris_stemmer.pre32(text)
        # text = self.isris_stemmer.suf32(text)
        
        # More synonym replacements after stemming
        
        # Positive reviews
        text = text.replace('5', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø±ÙˆØ¹Ù‡', 'Ù…Ù…ØªØ§Ø²')
        text = text.replace('Ø±ÙˆØ¹', 'Ù…Ù…ØªØ§Ø²')

        
        # Negative synonyms
        text = text.replace('Ø³ÙŠØ¡', 'Ø²ÙØª')  
        text = text.replace('Ø­Ø±Ø§Ù…', 'Ø²ÙØª') 
        text = text.replace('0', 'Ø²ÙØª')  
        text = text.replace('Ù…Ù‚Ø±Ù', 'Ø²ÙØª')  

        # Remove words that make conflicts
        text = text.replace('Ø¬Ø¯Ø§', '')  
        

        return text

      
        
class EnglishPreprocessor:
    def __init__(self):
        self.stop_words = set(stopwords.words('english'))
        self.tokenizer=ToktokTokenizer()
        self.lemmatizer = WordNetLemmatizer()
        self.stemmer = PorterStemmer()

    def preprocess(self, text):
        # Remove punctuation
        text = text.translate(str.maketrans('', '', string.punctuation))

        # Tokenize text and transform to lower cass
        tokens = word_tokenize(text.lower())

        # Remove stop words
        filtered_tokens = [token for token in tokens if token not in self.stop_words]

        # Lemmatize/stem
        lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in filtered_tokens]

        # Rejoin tokens into a string
        return ' '.join(lemmatized_tokens)



label_mapping = {-1: 0, 0: 1, 1: 2}

# Main function (Optionally define number of samples to preprocess, to process smaller batches for testing if required)
def preprocess_df(df, out_name, num_samples=-1, isPredict = False):
    
    # If num_rows is not -1 and less than the total rows, randomly sample the specified number of rows
    if num_samples != -1 and num_samples < len(df):
        df = df.sample(n=num_samples, random_state=42)  # random_state ensures reproducibility

    # Preprocess English and Arabic text data
    ar_pre = ArabicPreprocessor()
    en_pre = EnglishPreprocessor()
    
    # List for processed text
    processed_texts = []
    
    # Iterate over text and preprocess according to language
    for text in df['review_description']:
        try:
            lang = detect(text)
        except:
            # If language detection fails, default to Arabic
            lang = 'ar'

        if lang == 'en':
            processed_text = en_pre.preprocess(text)
        else:
            processed_text = ar_pre.preprocess(text)
        
        processed_texts.append(processed_text)
    
    # Replace text with preprocessed version
    df['review_description'] = processed_texts
    
    # Preprocess target values and save preprocessed data (only if data is labeled, i.e in training and testing, not prediction)
    if not isPredict:
        # Map sentiments from -1,0, 0 to 1, 1 ,2
        df['rating'] = df['rating'].map(label_mapping)
    
        # Save to Excel
        df.to_excel(f'preprocessed_{out_name}.xlsx', index=False)
    
    return df


